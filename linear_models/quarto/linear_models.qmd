---
title: "Linear Model Notes"
author: "Jake Baker"
toc: true
number-sections: true
highlight-style: pygments
format: 
  html: 
    code-fold: true
    html-math-method: katex
---

## Key Definitions

::: {#def-standard_normal}
A random vector $\mathbf{z} \in \mathbb{R^n}$ is standard normal **iff** components 
$(\mathbf{z_i})_{i=1}^n$
are independantly identically distributed $\mathcal{N}(0,1)$.
:::

::: {.callout-note}
If a vector in standard normal w.r.t one basis then it is standard normal w.r.t any basis.
:::

::: {#def-ols_lm}
An ordinary least squares linear model (OLM) provides an estimate $\hat{\beta}$ of unknown coefficent $\beta \in \mathbb{R^{p \times 1}}$ to the problem,

$$
\mathbf{y} = \mathbf{X} \beta + \mathbf{\varepsilon}
$$

that minimises $\| \hat{\varepsilon} \|$ for $\hat{\varepsilon} = \mathbf{y-X \hat{\beta}}$.

Items $\mathbf{y} \in \mathbb{R}^{n \times 1}, \mathbf{x} \in \mathbb{R^{n \times p}}$ are known.

We **assume** that $\dfrac{\varepsilon}{\sigma}$ is standard normal [@def-standard_normal]
$\Leftrightarrow \varepsilon \sim N(\mathbf{0, \sigma^2 I_n})$,
where we may not know $\sigma$.

:::

## Theorems

::: {#thm-line}
## Aline
The equation of any straight line, called a linear equation, can be written as:
$$
y = mx + b
$$
:::

See @thm-line.

## Section